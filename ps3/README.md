# Problem Set 3 — Regularization and Classification Methods

This folder contains all deliverables for Problem Set 3.

---

## Topics Covered

**Part I**: Conceptual and applied questions from Chapter 6 of *An Introduction to Statistical Learning (ISL)*  
- Bias-variance tradeoff for Lasso, Ridge, and non-linear methods  
- Behavior of model components under increasing complexity  
- Best subset selection with simulated data  
- Comparison of model selection techniques: Best Subset, Ridge, Lasso, and PCR  
- Model performance evaluation based on MSE and coefficient estimation error  

**Part II**: Applied questions from Chapter 4 of *ISL* on classification  
- Curse of dimensionality and its impact on KNN  
- Training vs. test error comparison for 1-NN vs. logistic regression  
- Derivation of quadratic discriminant analysis (QDA) decision boundaries  
- Mapping between binary logistic regression and softmax classification  

**Part III**: Empirical classification with the `Weekly` dataset  
- Logistic regression, LDA, QDA, KNN, and Naive Bayes models  
- Train/test split and model accuracy comparison  
- Feature selection and tuning (e.g., varying predictors, tuning K for KNN)  
- Interpretation of model coefficients and prediction performance

---

## Files

- `ps3.Rmd` — RMarkdown file with all code and written responses  
- `ps3.pdf` — Knitted PDF output of the RMarkdown file  

---

## Tools Used

- `R`, `ISLR2`, `ggplot2`, `dplyr`, `leaps`, `glmnet`, `pls`, `caret`, `MASS`, `class`, `e1071`



